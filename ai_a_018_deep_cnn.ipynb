{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/groundivy-dev1/Test01/blob/main/ai_a_018_deep_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qT6IO6QvO-x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIFJU-ITv1Ev",
        "outputId": "fe083be1-5569-4faa-db3f-56712d51bd4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using PyTorch version: 2.5.1+cu121, Device: cpu\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "print(f\"using PyTorch version: {torch.__version__}, Device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XmHUb0Jv1HW",
        "outputId": "791fd1f1-5c9d-4d87-917e-0d4eacf4af3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='CIFAR10_data/', train=True, download=True,\n",
        "                               transform=transform)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='CIFAR10_data/', train=False, download=True,\n",
        "                              transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhEp5LRXv1Jw",
        "outputId": "252376c8-3348-401c-fe69-255b546d6820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000\n",
            "42500 7500 10000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))\n",
        "\n",
        "train_dataset_size = int(len(train_dataset) * 0.85)\n",
        "validation_dataset_size = int(len(train_dataset) * 0.15)\n",
        "\n",
        "train_dataset, validation_dataset = random_split(train_dataset, [train_dataset_size, validation_dataset_size])\n",
        "\n",
        "print(len(train_dataset), len(validation_dataset), len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ28J8Xav1Ma"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "#BATCH_SIZE = 128\n",
        "\n",
        "train_dataset_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "validation_dataset_loader = DataLoader(dataset=validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_dataset_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0EwWsKHv1PN"
      },
      "outputs": [],
      "source": [
        "class MyCNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(1 * 1 * 256, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        self.dropout25 = nn.Dropout(p=0.25)\n",
        "        self.dropout50 = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        data = self.conv1(data)\n",
        "        data = torch.relu(data)\n",
        "        data = self.conv2(data)\n",
        "        data = torch.relu(data)\n",
        "        data = self.pooling(data)\n",
        "        data = self.dropout25(data)\n",
        "\n",
        "        data = self.conv3(data)\n",
        "        data = torch.relu(data)\n",
        "        data = self.conv4(data)\n",
        "        data = torch.relu(data)\n",
        "        data = self.pooling(data)\n",
        "        data = self.dropout25(data)\n",
        "\n",
        "        data = self.conv5(data)\n",
        "        data = torch.relu(data)\n",
        "        data = self.pooling(data)\n",
        "        data = self.dropout25(data)\n",
        "\n",
        "        data = self.conv6(data)\n",
        "        data = torch.relu(data)\n",
        "        data = self.pooling(data)\n",
        "        data = self.dropout25(data)\n",
        "\n",
        "        data = self.conv7(data)\n",
        "        data = torch.relu(data)\n",
        "        data = self.pooling(data)\n",
        "        data = self.dropout25(data)\n",
        "\n",
        "        data = data.view(-1, 1 * 1 * 256)\n",
        "\n",
        "        data = self.fc1(data)\n",
        "        data = torch.relu(data)\n",
        "        data = self.dropout50(data)\n",
        "\n",
        "        logits = self.fc2(data)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D92gl8Zfv1SR"
      },
      "outputs": [],
      "source": [
        "def model_train(dataloader, model, loss_function, optimizer):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss_sum = train_correct = train_total = 0\n",
        "\n",
        "    total_train_batch = len(dataloader)\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "\n",
        "        x_train = images.to(DEVICE)\n",
        "        y_train = labels.to(DEVICE)\n",
        "\n",
        "        outputs = model(x_train)\n",
        "        loss = loss_function(outputs, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_sum += loss.item()\n",
        "\n",
        "        train_total += y_train.size(0)\n",
        "        train_correct += ((torch.argmax(outputs, 1)==y_train)).sum().item()\n",
        "\n",
        "    train_avg_loss = train_loss_sum / total_train_batch\n",
        "    train_avg_accuracy = 100*train_correct / train_total\n",
        "\n",
        "    return (train_avg_loss, train_avg_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbuM5Nlcv1UR"
      },
      "outputs": [],
      "source": [
        "def model_evaluate(dataloader, model, loss_function, optimizer):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        val_loss_sum = val_correct = val_total = 0\n",
        "\n",
        "        total_val_batch = len(dataloader)\n",
        "\n",
        "        for images, labels in dataloader:\n",
        "\n",
        "            x_val = images.to(DEVICE)\n",
        "            y_val = labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(x_val)\n",
        "            loss = loss_function(outputs, y_val)\n",
        "\n",
        "            val_loss_sum += loss.item()\n",
        "\n",
        "            val_total += y_val.size(0)\n",
        "            val_correct += ((torch.argmax(outputs, 1)==y_val)).sum().item()\n",
        "\n",
        "        val_avg_loss = val_loss_sum / total_val_batch\n",
        "        val_avg_accuracy = 100*val_correct / val_total\n",
        "\n",
        "    return (val_avg_loss, val_avg_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nma1rR9waLL"
      },
      "outputs": [],
      "source": [
        "def model_test(dataloader, model):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        test_loss_sum = 0\n",
        "        test_correct=0\n",
        "        test_total = 0\n",
        "\n",
        "        total_test_batch = len(dataloader)\n",
        "\n",
        "        for images, labels in dataloader:\n",
        "\n",
        "            x_test = images.to(DEVICE)\n",
        "            y_test = labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(x_test)\n",
        "            loss = loss_function(outputs, y_test)\n",
        "\n",
        "            test_loss_sum += loss.item()\n",
        "\n",
        "            test_total += y_test.size(0)\n",
        "            test_correct += ((torch.argmax(outputs, 1)==y_test)).sum().item()\n",
        "\n",
        "        test_avg_loss = test_loss_sum / total_test_batch\n",
        "        test_avg_accuracy = 100*test_correct / test_total\n",
        "\n",
        "        print('accuracy:', test_avg_accuracy)\n",
        "        print('loss:', test_avg_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKrAjL_Rv1X7"
      },
      "outputs": [],
      "source": [
        "model = MyCNNModel().to(DEVICE)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c07hPcIkv1Z7",
        "outputId": "3e7b6736-5dce-4189-80c9-2eae69c3eb3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 01 train loss = 1.850 train acc = 27.598 val loss = 1.634 val acc = 36.800\n",
            "epoch: 02 train loss = 1.508 train acc = 42.991 val loss = 1.343 val acc = 50.093\n",
            "epoch: 03 train loss = 1.313 train acc = 52.179 val loss = 1.130 val acc = 59.693\n",
            "epoch: 04 train loss = 1.164 train acc = 58.508 val loss = 1.082 val acc = 62.027\n",
            "epoch: 05 train loss = 1.085 train acc = 61.635 val loss = 0.984 val acc = 65.040\n",
            "epoch: 06 train loss = 1.018 train acc = 63.951 val loss = 0.948 val acc = 66.213\n",
            "epoch: 07 train loss = 0.970 train acc = 65.911 val loss = 0.883 val acc = 69.080\n",
            "epoch: 08 train loss = 0.942 train acc = 67.287 val loss = 0.873 val acc = 68.973\n",
            "epoch: 09 train loss = 0.908 train acc = 68.445 val loss = 0.816 val acc = 71.560\n",
            "epoch: 10 train loss = 0.882 train acc = 69.668 val loss = 0.817 val acc = 71.933\n",
            "epoch: 11 train loss = 0.861 train acc = 70.275 val loss = 0.793 val acc = 72.733\n",
            "epoch: 12 train loss = 0.832 train acc = 71.219 val loss = 0.819 val acc = 71.733\n",
            "epoch: 13 train loss = 0.818 train acc = 71.438 val loss = 0.813 val acc = 72.520\n",
            "epoch: 14 train loss = 0.799 train acc = 72.287 val loss = 0.751 val acc = 74.760\n",
            "epoch: 15 train loss = 0.783 train acc = 72.894 val loss = 0.754 val acc = 74.560\n",
            "epoch: 16 train loss = 0.777 train acc = 73.499 val loss = 0.758 val acc = 74.320\n",
            "epoch: 17 train loss = 0.759 train acc = 74.141 val loss = 0.723 val acc = 75.227\n",
            "epoch: 18 train loss = 0.745 train acc = 74.278 val loss = 0.742 val acc = 74.013\n",
            "epoch: 19 train loss = 0.734 train acc = 74.969 val loss = 0.695 val acc = 76.427\n",
            "epoch: 20 train loss = 0.729 train acc = 75.009 val loss = 0.688 val acc = 76.427\n",
            "epoch: 21 train loss = 0.724 train acc = 75.209 val loss = 0.712 val acc = 75.973\n",
            "epoch: 22 train loss = 0.718 train acc = 75.372 val loss = 0.677 val acc = 76.827\n",
            "epoch: 23 train loss = 0.703 train acc = 75.979 val loss = 0.675 val acc = 77.213\n",
            "epoch: 24 train loss = 0.701 train acc = 76.329 val loss = 0.657 val acc = 77.813\n",
            "epoch: 25 train loss = 0.691 train acc = 76.638 val loss = 0.657 val acc = 77.747\n",
            "epoch: 26 train loss = 0.684 train acc = 76.751 val loss = 0.684 val acc = 76.933\n",
            "epoch: 27 train loss = 0.676 train acc = 76.932 val loss = 0.682 val acc = 77.480\n",
            "epoch: 28 train loss = 0.673 train acc = 76.802 val loss = 0.642 val acc = 78.080\n",
            "epoch: 29 train loss = 0.667 train acc = 77.482 val loss = 0.666 val acc = 77.640\n",
            "epoch: 30 train loss = 0.660 train acc = 77.802 val loss = 0.649 val acc = 77.960\n",
            "epoch: 31 train loss = 0.658 train acc = 77.875 val loss = 0.665 val acc = 77.440\n",
            "epoch: 32 train loss = 0.653 train acc = 78.113 val loss = 0.626 val acc = 78.907\n",
            "epoch: 33 train loss = 0.664 train acc = 77.576 val loss = 0.643 val acc = 78.653\n",
            "epoch: 34 train loss = 0.639 train acc = 78.412 val loss = 0.618 val acc = 79.280\n",
            "epoch: 35 train loss = 0.636 train acc = 78.358 val loss = 0.659 val acc = 77.920\n",
            "epoch: 36 train loss = 0.632 train acc = 78.784 val loss = 0.649 val acc = 78.267\n",
            "epoch: 37 train loss = 0.632 train acc = 78.814 val loss = 0.624 val acc = 79.027\n",
            "epoch: 38 train loss = 0.640 train acc = 78.551 val loss = 0.652 val acc = 77.680\n",
            "epoch: 39 train loss = 0.626 train acc = 78.969 val loss = 0.622 val acc = 79.587\n",
            "epoch: 40 train loss = 0.623 train acc = 79.089 val loss = 0.619 val acc = 79.520\n",
            "epoch: 41 train loss = 0.626 train acc = 78.929 val loss = 0.618 val acc = 79.467\n",
            "epoch: 42 train loss = 0.625 train acc = 79.052 val loss = 0.633 val acc = 78.813\n",
            "epoch: 43 train loss = 0.622 train acc = 79.071 val loss = 0.645 val acc = 78.560\n",
            "epoch: 44 train loss = 0.616 train acc = 79.207 val loss = 0.629 val acc = 79.240\n",
            "epoch: 45 train loss = 0.610 train acc = 79.652 val loss = 0.630 val acc = 79.027\n",
            "epoch: 46 train loss = 0.608 train acc = 79.607 val loss = 0.611 val acc = 80.080\n",
            "epoch: 47 train loss = 0.608 train acc = 79.616 val loss = 0.616 val acc = 79.827\n",
            "epoch: 48 train loss = 0.603 train acc = 79.598 val loss = 0.604 val acc = 80.360\n",
            "epoch: 49 train loss = 0.598 train acc = 80.049 val loss = 0.601 val acc = 80.133\n",
            "epoch: 50 train loss = 0.607 train acc = 79.588 val loss = 0.604 val acc = 80.253\n",
            "epoch: 51 train loss = 0.603 train acc = 79.760 val loss = 0.628 val acc = 79.080\n",
            "epoch: 52 train loss = 0.605 train acc = 79.918 val loss = 0.685 val acc = 77.507\n",
            "epoch: 53 train loss = 0.602 train acc = 79.962 val loss = 0.625 val acc = 79.560\n",
            "epoch: 54 train loss = 0.587 train acc = 80.398 val loss = 0.598 val acc = 80.227\n",
            "epoch: 55 train loss = 0.583 train acc = 80.224 val loss = 0.621 val acc = 80.187\n",
            "epoch: 56 train loss = 0.590 train acc = 80.226 val loss = 0.618 val acc = 79.667\n",
            "epoch: 57 train loss = 0.587 train acc = 80.372 val loss = 0.609 val acc = 79.987\n",
            "epoch: 58 train loss = 0.590 train acc = 80.449 val loss = 0.584 val acc = 80.400\n",
            "epoch: 59 train loss = 0.595 train acc = 80.134 val loss = 0.630 val acc = 79.400\n",
            "epoch: 60 train loss = 0.575 train acc = 80.511 val loss = 0.597 val acc = 80.427\n",
            "epoch: 61 train loss = 0.576 train acc = 80.732 val loss = 0.603 val acc = 80.267\n",
            "epoch: 62 train loss = 0.577 train acc = 80.616 val loss = 0.608 val acc = 80.147\n",
            "epoch: 63 train loss = 0.580 train acc = 80.838 val loss = 0.650 val acc = 79.107\n",
            "epoch: 64 train loss = 0.581 train acc = 80.725 val loss = 0.604 val acc = 79.907\n",
            "epoch: 65 train loss = 0.574 train acc = 80.951 val loss = 0.607 val acc = 80.120\n",
            "epoch: 66 train loss = 0.576 train acc = 80.576 val loss = 0.584 val acc = 81.120\n",
            "epoch: 67 train loss = 0.582 train acc = 80.591 val loss = 0.664 val acc = 78.427\n",
            "epoch: 68 train loss = 0.567 train acc = 81.066 val loss = 0.623 val acc = 79.360\n",
            "epoch: 69 train loss = 0.580 train acc = 80.809 val loss = 0.602 val acc = 80.640\n",
            "epoch: 70 train loss = 0.574 train acc = 80.904 val loss = 0.604 val acc = 80.573\n",
            "epoch: 71 train loss = 0.567 train acc = 81.261 val loss = 0.590 val acc = 80.787\n",
            "epoch: 72 train loss = 0.572 train acc = 81.054 val loss = 0.615 val acc = 79.627\n",
            "epoch: 73 train loss = 0.566 train acc = 81.329 val loss = 0.584 val acc = 81.413\n",
            "epoch: 74 train loss = 0.567 train acc = 81.344 val loss = 0.585 val acc = 81.373\n",
            "epoch: 75 train loss = 0.566 train acc = 81.412 val loss = 0.603 val acc = 80.347\n",
            "epoch: 76 train loss = 0.559 train acc = 81.565 val loss = 0.650 val acc = 79.933\n",
            "epoch: 77 train loss = 0.567 train acc = 81.207 val loss = 0.603 val acc = 80.533\n",
            "epoch: 78 train loss = 0.562 train acc = 81.600 val loss = 0.572 val acc = 81.733\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "train_loss_list = []\n",
        "train_accuracy_list = []\n",
        "\n",
        "val_loss_list = []\n",
        "val_accuracy_list = []\n",
        "\n",
        "start_time = datetime.now()\n",
        "EPOCHS = 200\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    #==============  model train  ================\n",
        "    train_avg_loss, train_avg_accuracy = model_train(train_dataset_loader, model, loss_function, optimizer)\n",
        "\n",
        "    train_loss_list.append(train_avg_loss)\n",
        "    train_accuracy_list.append(train_avg_accuracy)\n",
        "    #=============================================\n",
        "\n",
        "    #============  model evaluation  ==============\n",
        "    val_avg_loss, val_avg_accuracy = model_evaluate(validation_dataset_loader, model, loss_function, optimizer)\n",
        "\n",
        "    val_loss_list.append(val_avg_loss)\n",
        "    val_accuracy_list.append(val_avg_accuracy)\n",
        "    #============  model evaluation  ==============\n",
        "\n",
        "    print('epoch:', '%02d' % (epoch + 1),\n",
        "          'train loss =', '{:.3f}'.format(train_avg_loss), 'train acc =', '{:.3f}'.format(train_avg_accuracy),\n",
        "          'val loss =', '{:.3f}'.format(val_avg_loss), 'val acc =', '{:.3f}'.format(val_avg_accuracy))\n",
        "\n",
        "end_time = datetime.now()\n",
        "\n",
        "print('elapsed time => ', end_time-start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzeRNx8kv1cr"
      },
      "outputs": [],
      "source": [
        "# test dataset 으로 정확도 및 오차 테스트\n",
        "\n",
        "model_test(test_dataset_loader, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S88mjgXav1fS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Loss Trend')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "\n",
        "plt.plot(train_loss_list, label='train loss')\n",
        "plt.plot(val_loss_list, label='validation loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUo5mUWNv1h-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Accuracy Trend')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.grid()\n",
        "\n",
        "plt.plot(train_accuracy_list, label='train accuracy')\n",
        "plt.plot(val_accuracy_list, label='validation accuracy')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvl8mjqRv1kh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Loss Trend')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "plt.plot(train_loss_list, label='train')\n",
        "plt.plot(val_loss_list, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Accuracy Trend')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.grid()\n",
        "plt.plot(train_accuracy_list, label='train')\n",
        "plt.plot(val_accuracy_list, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZrnBDf1v1nY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/sRM+Xv3dl0IVIL/W5YrK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}